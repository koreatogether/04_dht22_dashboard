#!/usr/bin/env python3
"""
Arduino ì½”ë“œ ë©”íŠ¸ë¦­ìŠ¤ ë¶„ì„ ë„êµ¬

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- Arduino ì½”ë“œ ë¼ì¸ ìˆ˜ ë¶„ì„
- í•¨ìˆ˜ ë³µì¡ë„ ë¶„ì„
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
- ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜ì¡´ì„± ë¶„ì„
- ì½”ë“œ í’ˆì§ˆ ë©”íŠ¸ë¦­ìŠ¤
"""

import re
import os
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
import json


class ArduinoMetricsAnalyzer:
    def __init__(self):
        self.project_root = Path.cwd()
        self.arduino_path = self.project_root / "src" / "arduino"
        self.reports_dir = self.project_root / "tools" / "metrics" / "reports"
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        # Arduino íŒŒì¼ë“¤ ì°¾ê¸°
        self.arduino_files = list(self.arduino_path.rglob("*.ino"))
        self.cpp_files = list(self.arduino_path.rglob("*.cpp"))
        self.h_files = list(self.arduino_path.rglob("*.h"))
        
        self.all_files = self.arduino_files + self.cpp_files + self.h_files
        
    def analyze_line_metrics(self) -> Dict[str, Any]:
        """ë¼ì¸ ìˆ˜ ë©”íŠ¸ë¦­ìŠ¤ ë¶„ì„"""
        print("ğŸ“ Arduino ë¼ì¸ ìˆ˜ ë¶„ì„ ì¤‘...")
        
        metrics = {
            "timestamp": datetime.now().isoformat(),
            "files": {},
            "summary": {
                "total_files": 0,
                "total_lines": 0,
                "code_lines": 0,
                "comment_lines": 0,
                "blank_lines": 0,
                "preprocessor_lines": 0
            }
        }
        
        for file_path in self.all_files:
            file_metrics = self._analyze_single_file(file_path)
            metrics["files"][str(file_path)] = file_metrics
            
            # ìš”ì•½ì— ì¶”ê°€
            metrics["summary"]["total_files"] += 1
            metrics["summary"]["total_lines"] += file_metrics["total_lines"]
            metrics["summary"]["code_lines"] += file_metrics["code_lines"]
            metrics["summary"]["comment_lines"] += file_metrics["comment_lines"]
            metrics["summary"]["blank_lines"] += file_metrics["blank_lines"]
            metrics["summary"]["preprocessor_lines"] += file_metrics["preprocessor_lines"]
        
        print(f"âœ… ë¼ì¸ ë¶„ì„ ì™„ë£Œ - {metrics['summary']['total_files']}ê°œ íŒŒì¼")
        return metrics
    
    def _analyze_single_file(self, file_path: Path) -> Dict[str, Any]:
        """ë‹¨ì¼ íŒŒì¼ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                lines = f.readlines()
        except UnicodeDecodeError:
            # UTF-8ì´ ì•ˆë˜ë©´ ë‹¤ë¥¸ ì¸ì½”ë”© ì‹œë„
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    lines = f.readlines()
            except Exception as e:
                print(f"âš ï¸  íŒŒì¼ ì½ê¸° ì˜¤ë¥˜ {file_path}: {e}")
                return {"error": str(e)}
        
        metrics = {
            "total_lines": len(lines),
            "code_lines": 0,
            "comment_lines": 0,
            "blank_lines": 0,
            "preprocessor_lines": 0,
            "functions": [],
            "includes": [],
            "defines": []
        }
        
        in_multiline_comment = False
        
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            
            # ë¹ˆ ì¤„
            if not stripped:
                metrics["blank_lines"] += 1
                continue
            
            # ë©€í‹°ë¼ì¸ ì£¼ì„ ì²˜ë¦¬
            if "/*" in stripped and "*/" in stripped:
                # í•œ ì¤„ì— ì‹œì‘ê³¼ ëì´ ëª¨ë‘ ìˆëŠ” ê²½ìš°
                metrics["comment_lines"] += 1
                continue
            elif "/*" in stripped:
                in_multiline_comment = True
                metrics["comment_lines"] += 1
                continue
            elif "*/" in stripped:
                in_multiline_comment = False
                metrics["comment_lines"] += 1
                continue
            elif in_multiline_comment:
                metrics["comment_lines"] += 1
                continue
            
            # ë‹¨ì¼ ë¼ì¸ ì£¼ì„
            if stripped.startswith("//"):
                metrics["comment_lines"] += 1
                continue
            
            # ì „ì²˜ë¦¬ê¸° ì§€ì‹œë¬¸
            if stripped.startswith("#"):
                metrics["preprocessor_lines"] += 1
                
                # include ë¶„ì„
                if stripped.startswith("#include"):
                    include_match = re.search(r'#include\s*[<"]([^>"]+)[>"]', stripped)
                    if include_match:
                        metrics["includes"].append(include_match.group(1))
                
                # define ë¶„ì„
                elif stripped.startswith("#define"):
                    define_match = re.search(r'#define\s+(\w+)', stripped)
                    if define_match:
                        metrics["defines"].append(define_match.group(1))
                continue
            
            # í•¨ìˆ˜ ì •ì˜ ì°¾ê¸°
            function_match = re.search(r'(\w+\s+)?(\w+)\s*\([^)]*\)\s*\{?', stripped)
            if function_match and not stripped.startswith("if") and not stripped.startswith("while"):
                func_name = function_match.group(2)
                if func_name not in ["if", "while", "for", "switch"]:
                    metrics["functions"].append({
                        "name": func_name,
                        "line": i,
                        "signature": stripped
                    })
            
            # ì¼ë°˜ ì½”ë“œ ë¼ì¸
            metrics["code_lines"] += 1
        
        return metrics
    
    def analyze_complexity(self) -> Dict[str, Any]:
        """ì½”ë“œ ë³µì¡ë„ ë¶„ì„"""
        print("ğŸ§® Arduino ë³µì¡ë„ ë¶„ì„ ì¤‘...")
        
        complexity_data = {
            "timestamp": datetime.now().isoformat(),
            "files": {},
            "summary": {
                "total_functions": 0,
                "avg_complexity": 0,
                "max_complexity": 0,
                "complex_functions": []
            }
        }
        
        total_complexity = 0
        
        for file_path in self.all_files:
            file_complexity = self._analyze_file_complexity(file_path)
            complexity_data["files"][str(file_path)] = file_complexity
            
            for func in file_complexity.get("functions", []):
                complexity_data["summary"]["total_functions"] += 1
                func_complexity = func.get("complexity", 0)
                total_complexity += func_complexity
                
                if func_complexity > complexity_data["summary"]["max_complexity"]:
                    complexity_data["summary"]["max_complexity"] = func_complexity
                
                if func_complexity > 10:  # ë³µì¡ë„ 10 ì´ìƒì€ ë³µì¡í•œ í•¨ìˆ˜
                    complexity_data["summary"]["complex_functions"].append({
                        "file": str(file_path),
                        "function": func["name"],
                        "complexity": func_complexity
                    })
        
        if complexity_data["summary"]["total_functions"] > 0:
            complexity_data["summary"]["avg_complexity"] = total_complexity / complexity_data["summary"]["total_functions"]
        
        print(f"âœ… ë³µì¡ë„ ë¶„ì„ ì™„ë£Œ - í‰ê·  ë³µì¡ë„: {complexity_data['summary']['avg_complexity']:.1f}")
        return complexity_data
    
    def _analyze_file_complexity(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ë³„ ë³µì¡ë„ ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    content = f.read()
            except Exception as e:
                return {"error": str(e)}
        
        # í•¨ìˆ˜ë³„ ë³µì¡ë„ ê³„ì‚°
        functions = []
        
        # ê°„ë‹¨í•œ í•¨ìˆ˜ ì¶”ì¶œ (ì •í™•í•˜ì§€ ì•Šì§€ë§Œ ê·¼ì‚¬ì¹˜)
        function_pattern = r'(\w+\s+)?(\w+)\s*\([^)]*\)\s*\{([^}]*(?:\{[^}]*\}[^}]*)*)\}'
        matches = re.finditer(function_pattern, content, re.DOTALL)
        
        for match in matches:
            func_name = match.group(2)
            func_body = match.group(3)
            
            if func_name in ["if", "while", "for", "switch"]:
                continue
            
            # ìˆœí™˜ ë³µì¡ë„ ê³„ì‚° (ê°„ë‹¨í•œ ë²„ì „)
            complexity = 1  # ê¸°ë³¸ ë³µì¡ë„
            
            # ì¡°ê±´ë¬¸ ì¹´ìš´íŠ¸
            complexity += len(re.findall(r'\bif\b', func_body))
            complexity += len(re.findall(r'\belse\b', func_body))
            complexity += len(re.findall(r'\bwhile\b', func_body))
            complexity += len(re.findall(r'\bfor\b', func_body))
            complexity += len(re.findall(r'\bswitch\b', func_body))
            complexity += len(re.findall(r'\bcase\b', func_body))
            complexity += len(re.findall(r'\bcatch\b', func_body))
            complexity += len(re.findall(r'\b&&\b', func_body))
            complexity += len(re.findall(r'\b\|\|\b', func_body))
            
            functions.append({
                "name": func_name,
                "complexity": complexity,
                "lines": len(func_body.split('\n'))
            })
        
        return {"functions": functions}
    
    def analyze_memory_usage(self) -> Dict[str, Any]:
        """ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •"""
        print("ğŸ’¾ Arduino ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì • ì¤‘...")
        
        memory_data = {
            "timestamp": datetime.now().isoformat(),
            "estimated_flash": 0,
            "estimated_ram": 0,
            "libraries": [],
            "large_arrays": [],
            "string_literals": []
        }
        
        for file_path in self.all_files:
            file_memory = self._estimate_file_memory(file_path)
            memory_data["estimated_flash"] += file_memory["flash"]
            memory_data["estimated_ram"] += file_memory["ram"]
            memory_data["libraries"].extend(file_memory["libraries"])
            memory_data["large_arrays"].extend(file_memory["large_arrays"])
            memory_data["string_literals"].extend(file_memory["string_literals"])
        
        # ì¤‘ë³µ ì œê±°
        memory_data["libraries"] = list(set(memory_data["libraries"]))
        
        print(f"âœ… ë©”ëª¨ë¦¬ ì¶”ì • ì™„ë£Œ - Flash: ~{memory_data['estimated_flash']}B, RAM: ~{memory_data['estimated_ram']}B")
        return memory_data
    
    def _estimate_file_memory(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ë³„ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    content = f.read()
            except Exception:
                return {"flash": 0, "ram": 0, "libraries": [], "large_arrays": [], "string_literals": []}
        
        memory_data = {
            "flash": 0,
            "ram": 0,
            "libraries": [],
            "large_arrays": [],
            "string_literals": []
        }
        
        # ë¼ì´ë¸ŒëŸ¬ë¦¬ include ì°¾ê¸°
        includes = re.findall(r'#include\s*[<"]([^>"]+)[>"]', content)
        memory_data["libraries"] = includes
        
        # ê° ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ ëŒ€ëµì ì¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (ì¶”ì •)
        library_flash_cost = {
            "DHT.h": 2000,
            "ArduinoJson.h": 8000,
            "WiFi.h": 15000,
            "Ethernet.h": 12000,
            "SoftwareSerial.h": 1500,
            "Wire.h": 1000,
            "SPI.h": 800
        }
        
        for lib in includes:
            memory_data["flash"] += library_flash_cost.get(lib, 500)  # ê¸°ë³¸ 500ë°”ì´íŠ¸
        
        # í° ë°°ì—´ ì°¾ê¸°
        array_pattern = r'(\w+)\s+(\w+)\s*\[\s*(\d+)\s*\]'
        arrays = re.findall(array_pattern, content)
        
        for array_type, array_name, array_size in arrays:
            size = int(array_size)
            if size > 50:  # 50ê°œ ì´ìƒì˜ ìš”ì†Œë¥¼ ê°€ì§„ ë°°ì—´
                type_size = self._get_type_size(array_type)
                memory_usage = size * type_size
                memory_data["ram"] += memory_usage
                memory_data["large_arrays"].append({
                    "name": array_name,
                    "type": array_type,
                    "size": size,
                    "memory": memory_usage
                })
        
        # ë¬¸ìì—´ ë¦¬í„°ëŸ´ ì°¾ê¸°
        string_literals = re.findall(r'"([^"]*)"', content)
        for literal in string_literals:
            if len(literal) > 10:  # 10ì ì´ìƒì˜ ë¬¸ìì—´
                memory_data["ram"] += len(literal) + 1  # null terminator
                memory_data["string_literals"].append(literal)
        
        # ê¸°ë³¸ ì½”ë“œ í¬ê¸° ì¶”ì • (ë§¤ìš° ëŒ€ëµì )
        code_lines = len([line for line in content.split('\n') if line.strip() and not line.strip().startswith('//')])
        memory_data["flash"] += code_lines * 4  # ë¼ì¸ë‹¹ í‰ê·  4ë°”ì´íŠ¸ ì¶”ì •
        
        return memory_data
    
    def _get_type_size(self, type_name: str) -> int:
        """ë°ì´í„° íƒ€ì…ë³„ í¬ê¸° ë°˜í™˜"""
        type_sizes = {
            "char": 1,
            "byte": 1,
            "int": 2,
            "unsigned int": 2,
            "long": 4,
            "unsigned long": 4,
            "float": 4,
            "double": 4,  # Arduinoì—ì„œëŠ” floatì™€ ê°™ìŒ
            "bool": 1,
            "boolean": 1
        }
        return type_sizes.get(type_name.lower(), 4)  # ê¸°ë³¸ 4ë°”ì´íŠ¸
    
    def analyze_dependencies(self) -> Dict[str, Any]:
        """ì˜ì¡´ì„± ë¶„ì„"""
        print("ğŸ“¦ Arduino ì˜ì¡´ì„± ë¶„ì„ ì¤‘...")
        
        deps_data = {
            "timestamp": datetime.now().isoformat(),
            "libraries": {},
            "custom_includes": [],
            "defines": [],
            "dependency_graph": {}
        }
        
        all_includes = set()
        all_defines = set()
        
        for file_path in self.all_files:
            file_deps = self._analyze_file_dependencies(file_path)
            
            # ë¼ì´ë¸ŒëŸ¬ë¦¬ ì •ë³´ ìˆ˜ì§‘
            for lib in file_deps["libraries"]:
                if lib not in deps_data["libraries"]:
                    deps_data["libraries"][lib] = {
                        "used_in": [],
                        "type": "external" if lib.endswith(".h") and not lib.startswith("Arduino") else "system"
                    }
                deps_data["libraries"][lib]["used_in"].append(str(file_path))
                all_includes.add(lib)
            
            deps_data["custom_includes"].extend(file_deps["custom_includes"])
            all_defines.update(file_deps["defines"])
            
            deps_data["dependency_graph"][str(file_path)] = file_deps
        
        deps_data["defines"] = list(all_defines)
        deps_data["custom_includes"] = list(set(deps_data["custom_includes"]))
        
        print(f"âœ… ì˜ì¡´ì„± ë¶„ì„ ì™„ë£Œ - {len(all_includes)}ê°œ ë¼ì´ë¸ŒëŸ¬ë¦¬")
        return deps_data
    
    def _analyze_file_dependencies(self, file_path: Path) -> Dict[str, Any]:
        """íŒŒì¼ë³„ ì˜ì¡´ì„± ë¶„ì„"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            try:
                with open(file_path, 'r', encoding='latin-1') as f:
                    content = f.read()
            except Exception:
                return {"libraries": [], "custom_includes": [], "defines": []}
        
        # Include ë¶„ì„
        includes = re.findall(r'#include\s*[<"]([^>"]+)[>"]', content)
        
        # ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ì™€ ì»¤ìŠ¤í…€ include êµ¬ë¶„
        libraries = []
        custom_includes = []
        
        for include in includes:
            if include.endswith('.h') and ('/' not in include or include.startswith('Arduino')):
                libraries.append(include)
            else:
                custom_includes.append(include)
        
        # Define ë¶„ì„
        defines = re.findall(r'#define\s+(\w+)', content)
        
        return {
            "libraries": libraries,
            "custom_includes": custom_includes,
            "defines": defines
        }
    
    def generate_comprehensive_report(self, line_metrics: Dict, complexity_data: Dict, 
                                    memory_data: Dict, deps_data: Dict) -> None:
        """ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ë¦¬í¬íŠ¸
        comprehensive_data = {
            "timestamp": datetime.now().isoformat(),
            "project": "DHT22 Arduino Environmental Sensor",
            "line_metrics": line_metrics,
            "complexity": complexity_data,
            "memory": memory_data,
            "dependencies": deps_data,
            "summary": {
                "total_files": line_metrics["summary"]["total_files"],
                "total_lines": line_metrics["summary"]["total_lines"],
                "code_lines": line_metrics["summary"]["code_lines"],
                "total_functions": complexity_data["summary"]["total_functions"],
                "avg_complexity": complexity_data["summary"]["avg_complexity"],
                "estimated_flash": memory_data["estimated_flash"],
                "estimated_ram": memory_data["estimated_ram"],
                "library_count": len(deps_data["libraries"])
            }
        }
        
        json_report = self.reports_dir / f"arduino_metrics_{timestamp}.json"
        with open(json_report, 'w', encoding='utf-8') as f:
            json.dump(comprehensive_data, f, indent=2, ensure_ascii=False)
        
        # Markdown ë¦¬í¬íŠ¸
        md_report = self.reports_dir / f"arduino_metrics_{timestamp}.md"
        self._generate_markdown_report(md_report, comprehensive_data)
        
        print(f"\nğŸ“„ Arduino ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ:")
        print(f"   JSON: {json_report}")
        print(f"   Markdown: {md_report}")
    
    def _generate_markdown_report(self, report_path: Path, data: Dict) -> None:
        """Markdown ë¦¬í¬íŠ¸ ìƒì„±"""
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(f"""# Arduino ì½”ë“œ ë©”íŠ¸ë¦­ìŠ¤ ë¦¬í¬íŠ¸

## ğŸ“Š í”„ë¡œì íŠ¸ ê°œìš”
- **í”„ë¡œì íŠ¸**: {data['project']}
- **ë¶„ì„ ì‹œê°„**: {data['timestamp']}
- **ì´ íŒŒì¼ ìˆ˜**: {data['summary']['total_files']}ê°œ
- **ì´ ë¼ì¸ ìˆ˜**: {data['summary']['total_lines']}ì¤„

## ğŸ“ ë¼ì¸ ìˆ˜ í†µê³„
- **ì½”ë“œ ë¼ì¸**: {data['summary']['code_lines']}ì¤„
- **ì£¼ì„ ë¼ì¸**: {data['line_metrics']['summary']['comment_lines']}ì¤„
- **ë¹ˆ ë¼ì¸**: {data['line_metrics']['summary']['blank_lines']}ì¤„
- **ì „ì²˜ë¦¬ê¸°**: {data['line_metrics']['summary']['preprocessor_lines']}ì¤„
- **ì£¼ì„ ë¹„ìœ¨**: {(data['line_metrics']['summary']['comment_lines'] / max(data['summary']['total_lines'], 1) * 100):.1f}%

## ğŸ§® ë³µì¡ë„ ë¶„ì„
- **ì´ í•¨ìˆ˜ ìˆ˜**: {data['summary']['total_functions']}ê°œ
- **í‰ê·  ë³µì¡ë„**: {data['summary']['avg_complexity']:.1f}
- **ìµœëŒ€ ë³µì¡ë„**: {data['complexity']['summary']['max_complexity']}
- **ë³µì¡í•œ í•¨ìˆ˜**: {len(data['complexity']['summary']['complex_functions'])}ê°œ

## ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶”ì •
- **Flash ë©”ëª¨ë¦¬**: ~{data['summary']['estimated_flash']:,}ë°”ì´íŠ¸
- **RAM ì‚¬ìš©ëŸ‰**: ~{data['summary']['estimated_ram']:,}ë°”ì´íŠ¸
- **ì‚¬ìš© ë¼ì´ë¸ŒëŸ¬ë¦¬**: {data['summary']['library_count']}ê°œ

### ì£¼ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
""")
            
            for lib, info in data['dependencies']['libraries'].items():
                f.write(f"- **{lib}**: {len(info['used_in'])}ê°œ íŒŒì¼ì—ì„œ ì‚¬ìš©\n")
            
            f.write(f"""
## ğŸ¯ ê¶Œì¥ì‚¬í•­
""")
            
            # ê¶Œì¥ì‚¬í•­ ìƒì„±
            recommendations = []
            
            if data['summary']['avg_complexity'] > 10:
                recommendations.append("- í‰ê·  ë³µì¡ë„ê°€ ë†’ìŠµë‹ˆë‹¤. í•¨ìˆ˜ë¥¼ ë” ì‘ê²Œ ë¶„í• í•˜ëŠ” ê²ƒì„ ê³ ë ¤í•˜ì„¸ìš”")
            
            if len(data['complexity']['summary']['complex_functions']) > 0:
                recommendations.append(f"- {len(data['complexity']['summary']['complex_functions'])}ê°œì˜ ë³µì¡í•œ í•¨ìˆ˜ê°€ ìˆìŠµë‹ˆë‹¤. ë¦¬íŒ©í† ë§ì„ ê³ ë ¤í•˜ì„¸ìš”")
            
            comment_ratio = data['line_metrics']['summary']['comment_lines'] / max(data['summary']['total_lines'], 1) * 100
            if comment_ratio < 15:
                recommendations.append("- ì£¼ì„ ë¹„ìœ¨ì„ 15% ì´ìƒìœ¼ë¡œ ëŠ˜ë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤")
            
            if data['summary']['estimated_flash'] > 20000:
                recommendations.append("- Flash ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. ì½”ë“œ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”")
            
            if data['summary']['estimated_ram'] > 1500:
                recommendations.append("- RAM ì‚¬ìš©ëŸ‰ì´ ë†’ìŠµë‹ˆë‹¤. í° ë°°ì—´ì´ë‚˜ ë¬¸ìì—´ì„ ìµœì í™”í•˜ì„¸ìš”")
            
            if not recommendations:
                recommendations.append("- í˜„ì¬ ì½”ë“œ í’ˆì§ˆì´ ìš°ìˆ˜í•©ë‹ˆë‹¤! ğŸ‰")
            
            for rec in recommendations:
                f.write(f"{rec}\n")


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ”§ Arduino ì½”ë“œ ë©”íŠ¸ë¦­ìŠ¤ ë¶„ì„ ì‹œì‘")
    print("=" * 60)
    
    analyzer = ArduinoMetricsAnalyzer()
    
    if not analyzer.all_files:
        print("âŒ Arduino íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   ê²½ë¡œ í™•ì¸: {analyzer.arduino_path}")
        return
    
    print(f"ğŸ“ ë°œê²¬ëœ íŒŒì¼: {len(analyzer.all_files)}ê°œ")
    for file_path in analyzer.all_files:
        print(f"   - {file_path}")
    
    # ë¶„ì„ ì‹¤í–‰
    line_metrics = analyzer.analyze_line_metrics()
    complexity_data = analyzer.analyze_complexity()
    memory_data = analyzer.analyze_memory_usage()
    deps_data = analyzer.analyze_dependencies()
    
    # ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±
    analyzer.generate_comprehensive_report(line_metrics, complexity_data, memory_data, deps_data)
    
    print("\nğŸ‰ Arduino ë©”íŠ¸ë¦­ìŠ¤ ë¶„ì„ ì™„ë£Œ!")


if __name__ == "__main__":
    main()